{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=10,filename=\"/content/logging.log\",mode='a')\n",
        "logging.warning(f'Hello')"
      ],
      "metadata": {
        "id": "RPn4P00YEPhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a51b37-da1d-4b77-fe60-0f52dbad3184"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Ankit-Raj-002/Salz.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx5TfeQgpZJ0",
        "outputId": "94015ca5-e0ee-4330-f2d7-311d53ec9bf1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Salz'...\n",
            "remote: Enumerating objects: 523, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 523 (delta 6), reused 0 (delta 0), pack-reused 509\u001b[K\n",
            "Receiving objects: 100% (523/523), 17.72 MiB | 19.42 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install diffusers transformers accelerate scipy safetensors\n",
        "!pip install gradio\n",
        "!pip install face_recognition\n",
        "!pip install openai\n",
        "!pip install google-search-results\n",
        "!pip install stability-sdk"
      ],
      "metadata": {
        "id": "lOwblqhF94qG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfef123-5544-4957-9568-32f98a0500aa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-wjz7o8na\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-wjz7o8na\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 102b5ff4a813eea848bb82ff2f451e0f6b17b30c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (0.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.27.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.0.dev0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.0.dev0) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.27.0.dev0) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.9/dist-packages (0.14.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.0.dev0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (0.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (1.10.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.9/dist-packages (0.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from diffusers) (3.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from diffusers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from diffusers) (2.25.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from diffusers) (8.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from diffusers) (6.0.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from diffusers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from diffusers) (0.13.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.10.0->diffusers) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata->diffusers) (3.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.9/dist-packages (3.20.1)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.9/dist-packages (from gradio) (10.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from gradio) (3.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from gradio) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from gradio) (4.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.9/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.9/dist-packages (from gradio) (3.17)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.9/dist-packages (from gradio) (0.94.0)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.9/dist-packages (from gradio) (0.23.3)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.9/dist-packages (from gradio) (0.3.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.9/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.9/dist-packages (from gradio) (0.21.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from gradio) (2023.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from gradio) (1.10.5)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.9/dist-packages (from gradio) (3.8.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.9/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.9/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from gradio) (2.25.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.9/dist-packages (from gradio) (23.1.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (3.1.0)\n",
            "Requirement already satisfied: starlette<0.27.0,>=0.26.0 in /usr/local/lib/python3.9/dist-packages (from fastapi->gradio) (0.26.0.post1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (0.16.3)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (4.39.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->gradio) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->gradio) (4.0.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/dist-packages (from uvicorn->gradio) (0.14.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn->gradio) (8.1.3)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.9/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.9/dist-packages (1.3.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (19.24.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from face_recognition) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.4.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (0.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.9/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from google-search-results) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->google-search-results) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->google-search-results) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->google-search-results) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->google-search-results) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stability-sdk in /usr/local/lib/python3.9/dist-packages (0.3.2)\n",
            "Requirement already satisfied: grpcio==1.48.1 in /usr/local/lib/python3.9/dist-packages (from stability-sdk) (1.48.1)\n",
            "Requirement already satisfied: protobuf==3.19.5 in /usr/local/lib/python3.9/dist-packages (from stability-sdk) (3.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from stability-sdk) (8.4.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/dist-packages (from stability-sdk) (1.0.0)\n",
            "Requirement already satisfied: grpcio-tools==1.48.1 in /usr/local/lib/python3.9/dist-packages (from stability-sdk) (1.48.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.9/dist-packages (from grpcio==1.48.1->stability-sdk) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from grpcio-tools==1.48.1->stability-sdk) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ti-lAvGP94su"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VU4P_vaTpGDu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../../content/Salz"
      ],
      "metadata": {
        "id": "kYNQxdZTABLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12b0975-d369-40cd-b547-e1629c9db9e9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Salz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "8PgOMm34AVWo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "from diffusers import StableDiffusionDepth2ImgPipeline\n",
        "from PIL import Image\n",
        "import time\n",
        "current_time = time.asctime()"
      ],
      "metadata": {
        "id": "j_ehAlKJnKxk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "from PIL import Image\n",
        "from stability_sdk import client\n",
        "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
        "\n",
        "# Our Host URL should not be prepended with \"https\" nor should it have a trailing slash.\n",
        "os.environ['STABILITY_HOST'] = 'grpc.stability.ai:443' #----------This is in env"
      ],
      "metadata": {
        "id": "UpkG6nCOEox4"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['STABILITY_KEY'] = 'sk-mw159yHTHVawVQu0KxVomhCeGCB6Nh4MyFuwg6HfpsVi0QTP'"
      ],
      "metadata": {
        "id": "wz293XNrFIrt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stability_api = client.StabilityInference(\n",
        "    key=os.environ['STABILITY_KEY'], # API Key reference.\n",
        "    verbose=True, # Print debug messages.\n",
        "    engine=\"stable-diffusion-512-v2-1\", # Set the engine to use for generation. For SD 2.0 use \"stable-diffusion-v2-0\".\n",
        "    # Available engines: stable-diffusion-v1 stable-diffusion-v1-5 stable-diffusion-512-v2-0 stable-diffusion-768-v2-0\n",
        "    # stable-diffusion-512-v2-1 stable-diffusion-768-v2-1 stable-inpainting-v1-0 stable-inpainting-512-v2-0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeleUWTTFIuU",
        "outputId": "70cb4fbe-effd-44fc-ec96-30b3331f6969"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stability_sdk.client:Opening channel to grpc.stability.ai:443\n",
            "INFO:stability_sdk.client:Channel opened to grpc.stability.ai:443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up our initial generation parameters.\n",
        "\n",
        "prompt =\"photo of bespectacled woman, long curly blue hair, bright green eyes, freckled complexion, photorealistic, colorful, highly detailed 4k, realistic photo\"\n",
        "def transform_ncuda(img,prompt,cfg=8.0,stps=30,sc=0.8):\n",
        "  answers2 = stability_api.generate(\n",
        "      prompt=f\"{prompt}\",\n",
        "      init_image=img, # Assign our previously generated img as our Initial Image for transformation.\n",
        "      start_schedule=sc, # Set the strength of our prompt in relation to our initial image.\n",
        "      steps=stps,# If attempting to transform an image that was previously generated with our API,\n",
        "                      # initial images benefit from having their own distinct seed rather than using the seed of the original image generation.\n",
        "      # Amount of inference steps performed on image generation. Defaults to 30.\n",
        "      cfg_scale=cfg, # Influences how strongly your generation is guided to match your prompt.\n",
        "                    # Setting this value higher increases the strength in which it tries to match your prompt.\n",
        "                    # Defaults to 7.0 if not specified.\n",
        "      width=512, # Generation width, defaults to 512 if not included.\n",
        "      height=512, # Generation height, defaults to 512 if not included.\n",
        "      sampler=generation.SAMPLER_K_DPMPP_2M # Choose which sampler we want to denoise our generation with.\n",
        "                                                  # Defaults to k_dpmpp_2m if not specified. Clip Guidance only supports ancestral samplers.\n",
        "                                                  # (Available Samplers: ddim, plms, k_euler, k_euler_ancestral, k_heun, k_dpm_2, k_dpm_2_ancestral, k_dpmpp_2s_ancestral, k_lms, k_dpmpp_2m)\n",
        "  )\n",
        "\n",
        "  # Set up our warning to print to the console if the adult content classifier is tripped.\n",
        "  # If adult content classifier is not tripped, display generated image.\n",
        "  for resp in answers2:\n",
        "      for artifact in resp.artifacts:\n",
        "          if artifact.finish_reason == generation.FILTER:\n",
        "              warnings.warn(\n",
        "                  \"Your request activated the API's safety filters and could not be processed.\"\n",
        "                  \"Please modify the prompt and try again.\")\n",
        "          if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "              global img2\n",
        "              img2 = Image.open(io.BytesIO(artifact.binary))\n",
        "              return img2\n",
        "            # img2.save(str(artifact.seed)+ \"-img2img.png\") # Save our generated image with its seed number as the filename and the img2img suffix so that we know this is our transformed image.\n"
      ],
      "metadata": {
        "id": "iEAGxtJMFGtu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_stability(prompt):\n",
        "# Set up our initial generation parameters.\n",
        "  answers = stability_api.generate(\n",
        "      prompt=f\"{prompt}\",\n",
        "       # If a seed is provided, the resulting generated image will be deterministic.\n",
        "                      # What this means is that as long as all generation parameters remain the same, you can always recall the same image simply by generating it again.\n",
        "                      # Note: This isn't quite the case for Clip Guided generations, which we'll tackle in a future example notebook.\n",
        "      steps=30, # Amount of inference steps performed on image generation. Defaults to 30.\n",
        "      cfg_scale=8.0, # Influences how strongly your generation is guided to match your prompt.\n",
        "                    # Setting this value higher increases the strength in which it tries to match your prompt.\n",
        "                    # Defaults to 7.0 if not specified.\n",
        "      width=512, # Generation width, defaults to 512 if not included.\n",
        "      height=512, # Generation height, defaults to 512 if not included.\n",
        "      samples=1, # Number of images to generate, defaults to 1 if not included.\n",
        "      sampler=generation.SAMPLER_K_DPMPP_2M # Choose which sampler we want to denoise our generation with.\n",
        "                                                  # Defaults to k_dpmpp_2m if not specified. Clip Guidance only supports ancestral samplers.\n",
        "                                                  # (Available Samplers: ddim, plms, k_euler, k_euler_ancestral, k_heun, k_dpm_2, k_dpm_2_ancestral, k_dpmpp_2s_ancestral, k_lms, k_dpmpp_2m)\n",
        "  )\n",
        "\n",
        "  # Set up our warning to print to the console if the adult content classifier is tripped.\n",
        "  # If adult content classifier is not tripped, save generated images.\n",
        "  for resp in answers:\n",
        "      for artifact in resp.artifacts:\n",
        "          if artifact.finish_reason == generation.FILTER:\n",
        "              warnings.warn(\n",
        "                  \"Your request activated the API's safety filters and could not be processed.\"\n",
        "                  \"Please modify the prompt and try again.\")\n",
        "          if artifact.type == generation.ARTIFACT_IMAGE:\n",
        "              img = Image.open(io.BytesIO(artifact.binary))\n",
        "              # img.save(str(artifact.seed)+ \".png\") # Save our generated images with their seed number as the filename.\n",
        "              return img"
      ],
      "metadata": {
        "id": "HlOhF-RrFGwN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "global cuda_error1\n",
        "cuda_error1 = 0\n",
        "try:\n",
        "  device = \"cuda\"\n",
        "  model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "  pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n",
        "  pipe = pipe.to(device)\n",
        "except:\n",
        "  cuda_error1 = 1"
      ],
      "metadata": {
        "id": "xpGSlx-nqTPp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "45c8df2194ab4fbf8773a4f1206552e7",
            "eb84d36ed22c45669c1cd05173cd4714",
            "a9ef07cddbb24ea389890e935c8190cf",
            "42b3b6757a3f41efa1bd10b544d523c8",
            "0cffc9d5a633449dbce2ad11d3ceab63",
            "f319027e5b384a5588bc36111ecab092",
            "c6ddfd17c6e846bc85842574460d3969",
            "f4100192b5cb44efb99ab36eee808966",
            "647e89ebd9cc415cbe970fef56fa9511",
            "3c7d351928da45b8b79f62e351f26361",
            "c6d07b87035e4a41b0f135dcb01d5392"
          ]
        },
        "outputId": "d3115855-21c6-4025-c14f-e9434396d507"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45c8df2194ab4fbf8773a4f1206552e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_error1"
      ],
      "metadata": {
        "id": "0a0PaxS3Hxht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7648b369-57cd-4307-dcb6-4739cc6a913e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NeEa4ExYIbmu"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global cuda_error2\n",
        "cuda_error2 = 0\n",
        "try:\n",
        "  pipe1 = StableDiffusionDepth2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-2-depth\",\n",
        "    torch_dtype=torch.float16,\n",
        "  ).to(\"cuda\")\n",
        "except:\n",
        "  cuda_error2 = 1"
      ],
      "metadata": {
        "id": "Y25reVQ2nGQH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cd4f2c662ed243c0ba8687bbe1437a96",
            "176022374e9d4776acee17d165414936",
            "80057139469c49e9b130edda63159e30",
            "6bc059be8bbb4feb86e8da7c39607b5d",
            "618edea2de804694affa5cec90d49db8",
            "7f2b1bbf19af4b099334a67ad9399bd0",
            "6b2ede83d687421d9269ed11fec36a25",
            "8af98c87f3a643dc8a62416f1fef24b8",
            "3a67d5a754884d58acb961566515ce12",
            "b73e638f26194f19972d94e23aee4081",
            "c3667d3bdc7f469dbec821ff1bdbbc59"
          ]
        },
        "outputId": "023ac558-4f38-4527-e99d-0973ff2a2cd5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd4f2c662ed243c0ba8687bbe1437a96"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_error2"
      ],
      "metadata": {
        "id": "W50gLslcqMqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce60e07-dce7-49cc-8590-69175a83ddca"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt='portrait of bespectacled woman, long curly blue hair, bright green eyes, photorealistic, colorful, highly detailed 4k'\n",
        "\n",
        "n_prompt='ugly, boring, bad anatomy'"
      ],
      "metadata": {
        "id": "Bsj9BAlfnGTW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nimage = Image.open(\"img1.png\").convert('RGB')\n",
        "# images = pipe(prompt=prompt, image=nimage,negative_prompt=n_prompt, strength=1, guidance_scale=15).images\n",
        "# im = np.asarray(images[0])\n",
        "# images[0]"
      ],
      "metadata": {
        "id": "VrMweixAiVMC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(init_image,prompt,n_prompt):\n",
        "  if cuda_error2==0:\n",
        "    try:\n",
        "      image1 = pipe1(prompt=prompt, image=init_image, negative_prompt=n_prompt, strength=0.8).images[0]\n",
        "    except:\n",
        "      image1 = transform_ncuda(init_image,prompt)\n",
        "  # image1.save(\"img1.png\")\n",
        "  # nimage = Image.open(\"img1.png\")\n",
        "  else:\n",
        "    image1 = transform_ncuda(init_image,prompt)\n",
        "  im = np.asarray(image1)\n",
        "  return im"
      ],
      "metadata": {
        "id": "tonK57yL94vD"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform1(img,prompt,n_prompt):\n",
        "  img.save(\"img1.png\")\n",
        "  nimage = Image.open(\"img1.png\").convert('RGB')\n",
        "  if cuda_error1==0:\n",
        "    try:\n",
        "      images = pipe(prompt=prompt, image=nimage,negative_prompt=n_prompt, strength=1, guidance_scale=15).images\n",
        "      im = np.asarray(images[0])\n",
        "    except:\n",
        "      image = transform_ncuda(img,prompt,15,50,0.95)\n",
        "      im = np.asarray(image)\n",
        "  # image1.save(\"img1.png\")\n",
        "  # nimage = Image.open(\"img1.png\")\n",
        "  else:\n",
        "    image = transform_ncuda(img,prompt,15,50,0.95)\n",
        "    im = np.asarray(image)\n",
        "  return im"
      ],
      "metadata": {
        "id": "MK3H-gc2j1O2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nimage = Image.open(\"img1.png\")\n",
        "# prompt = \"photo of bespectacled woman, long curly blue hair, bright green eyes, freckled complexion, photorealistic, colorful, highly detailed 4k, realistic photo\"\n",
        "# n_prompt = \"ugly, boring, bad anatomy\"\n",
        "# pipe(prompt=prompt, image=nimage,negative_prompt=n_prompt, strength=1, guidance_scale=15).images"
      ],
      "metadata": {
        "id": "rXQ6dKY4j1Ul"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib"
      ],
      "metadata": {
        "id": "OgoNV2qGw1ty"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############### Knowlwdge graph\n",
        "\n",
        "import os\n",
        "\n",
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "PROMPT = \"colorful portrait 25 year bespectacled woman with long, curly skyblue hair and bright green eyes. She has a small, upturned nose and a freckled complexion. She is approximately 5'5 tall and has a thin build\"\n",
        "def generate(PROMPT,model):\n",
        "#     PROMPT = \"An eco-friendly computer from the 90s in the style of vaporwave\"\"Dall-E\",\"StableDiffusion\"\n",
        "  if model==\"Dall-E\":\n",
        "    response = openai.Image.create(\n",
        "    prompt=PROMPT,\n",
        "    n=1,\n",
        "    size=\"256x256\",\n",
        ")\n",
        "    x = response[\"data\"][0][\"url\"]\n",
        "    urllib.request.urlretrieve(x,\"file\")\n",
        "    img = Image.open(\"file\")\n",
        "  else:\n",
        "    try:\n",
        "      img = generate_stability(PROMPT)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "  return np.asarray(img)"
      ],
      "metadata": {
        "id": "FwEzCf_J94xj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import face_recognition\n",
        "except:\n",
        "  pass\n",
        "import pickle\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "metadata": {
        "id": "pXmzinHmAyPJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch"
      ],
      "metadata": {
        "id": "mMqVUN11wXVH"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from base64 import b64encode"
      ],
      "metadata": {
        "id": "2Otv_xQm7ukA"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "80qh6r9d-11K"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_ENDPOINT = \"https://api.imgbb.com/1/upload\"\n",
        "API_KEY = \"51e7720f96af8eb5179e772e443c0c1e\"\n",
        "\n",
        "# path_raw = input(\"Enter the image path: \")\n",
        "# path = Path(path_raw)\n",
        "# path = path_raw.replace(\"\\\\\", \"/\")\n",
        "\n",
        "# def imgLink(path):\n",
        "# path = Path(\"/content/drive/MyDrive/Salz/dannydevito.png\")\n",
        "def imgLink(image):\n",
        "    pil_image = image.convert('RGB') \n",
        "    open_cv_image = np.array(pil_image) \n",
        "    cv2.imwrite(\"search.png\",open_cv_image)\n",
        "    path = Path(\"search.png\")\n",
        "    with open(path, \"rb\") as image:\n",
        "        image_data = b64encode(image.read()).decode()\n",
        "        # image_data = image\n",
        "        payload = {\n",
        "            \"key\": API_KEY,\n",
        "            \"image\": image_data\n",
        "        }\n",
        "\n",
        "        # Send the API request\n",
        "        response = requests.post(API_ENDPOINT, payload)\n",
        "        # print(response)\n",
        "        # # Get the generated link from the API response\n",
        "        response_json = response.json() # \n",
        "        # print(\"Response json:\", response_json)\n",
        "        image_url = response_json[\"data\"][\"url\"]\n",
        "\n",
        "        # print(\"Generated link:\", image_url)\n",
        "        return image_url"
      ],
      "metadata": {
        "id": "tBJWjqxx7oKJ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####### KNOWLEDGE GRAPH\n",
        "import os\n",
        "import openai\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "openai.api_key =\"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\"\n",
        "\n",
        "# os.getenv()\n",
        "PROMPT = \"Ankit went to the market. He called Raj then.\"\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=f\"Given a prompt, extrapolate as many relationships as possible from it and provide a list of updates.\\n\\nIf an update is a relationship, provide [ENTITY 1, RELATIONSHIP, ENTITY 2]. The relationship is directed, so the order matters.\\n\\nIf an update is related to deleting an entity, provide [\\\"DELETE\\\", ENTITY].\\n\\nExample:\\nprompt: Alice is Bob's roommate. Alice likes music. Her roommate likes sports\\nupdates:\\n[[\\\"Alice\\\", \\\"roommate\\\", \\\"Bob\\\"],[\\\"Alice\\\",\\\"likes\\\",\\\"music\\\"],[\\\"Bob\\\",\\\"likes\\\",\\\"sports\\\"]]\\n\\nprompt: {PROMPT}\\nupdates:\",\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "r = response[\"choices\"][0][\"text\"]\n",
        "r = r[2:]\n",
        "r = r.replace(\"[\",'').replace(\"]\",\"\")\n",
        "r = r.split(\",\")\n",
        "t = []\n",
        "for i in range(len(r)//3):\n",
        "  t.append(r[3*i:3*i+3])\n",
        "# t = [['\"Ankit\"', '\"went_to\"', '\"market\"'], ['\"Ankit\"', '\"called\"', '\"Raj\"']]\n",
        "import networkx as nx\n",
        "G = nx.Graph()\n",
        "for i in t:\n",
        "  G.add_node(i[0])\n",
        "  G.add_node(i[2])\n",
        "  G.add_edge(i[0],i[2])\n",
        "pos = nx.spring_layout(G)\n",
        "nx.draw(G,pos,labels={node: node for node in G.nodes()})\n",
        "nx.draw_networkx_edge_labels(\n",
        "    G, pos,\n",
        "    edge_labels={(t[0][0], t[0][2]): t[0][1], \n",
        "                 (t[1][0], t[1][2]): t[1][1]\n",
        "                },\n",
        "    font_color='red'\n",
        ")\n",
        "\n",
        "plt.savefig('/content/graph.png')\n",
        "img = Image.open('/content/graph.png')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "AMJFIH79AFCR",
        "outputId": "03e897b7-3a60-4f26-e88a-bbe05e401bdc"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl6082L5Qlxk",
        "outputId": "15a6b015-30c5-403a-94f4-e3550f0fca2d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install networkx"
      ],
      "metadata": {
        "id": "vjOxugETSuIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06105071-3ddb-4d73-90a7-7acaff3750c8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def google_search(image):\n",
        "  image_url = imgLink(image)\n",
        "  params = {\n",
        "  \"engine\": \"google_lens\",\n",
        "  \"url\": image_url,\n",
        "  \"hl\": \"en\",\n",
        "  \"api_key\": \"9f32067b9dd74d6e94153036003ec0e6e24d54b36ffb09a340f9004012fdae98\"\n",
        "  }\n",
        "  search = GoogleSearch(params)\n",
        "  result = search.get_dict()\n",
        "  t = ''\n",
        "  try:\n",
        "    for i in range(len(result['knowledge_graph'])):\n",
        "      t = t+ \"Title : \"+result['knowledge_graph'][i]['title']+\"\\n\"\n",
        "      source = result[\"knowledge_graph\"][i]['images'][0]['source']\n",
        "      t+=source+\"\\n\"\n",
        "  except:\n",
        "    t = \"Not Found\"\n",
        "  try:\n",
        "    for i in range(0,min(2,len(result['visual_matches']))):\n",
        "      t = t+ \"Title : \"+result['visual_matches'][i]['title']+\"\\n\"\n",
        "      source = result['visual_matches'][i]['source']\n",
        "      t+=source+\"\\n\"\n",
        "  except:\n",
        "    t = \"Not Found\"\n",
        "\n",
        "  try:\n",
        "    img_link = result[\"visual_matches\"][0]['thumbnail']\n",
        "    urllib.request.urlretrieve(img_link,\"file\")\n",
        "    img = Image.open(\"file\")\n",
        "    img = np.asarray(img)\n",
        "  except:\n",
        "    img = image\n",
        "  return t,img"
      ],
      "metadata": {
        "id": "QN7mSasa4tR-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_folder_path = 'Images'\n",
        "#find path of xml file containing haarcascade file \n",
        "# cascPathface = os.path.dirname(\n",
        "#  cv2.__file__) + \"/data/haarcascade_frontalface_default.xml\"\n",
        "cascPathface = \"/content/Salz/haarcascade_frontalface_default.xml\"\n",
        "# cascPathface = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
        "# load the harcaascade in the cascade classifier\n",
        "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
        "# load the known faces and embeddings saved in last file\n",
        "data = pickle.loads(open('face_enc', \"rb\").read())"
      ],
      "metadata": {
        "id": "5kdE-nlX9TC0"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_database(ima):\n",
        "    # file_bytes = np.asarray(bytearray(image_upload.read()), dtype=np.uint8) # https://github.com/streamlit/streamlit/issues/888\n",
        "    # opencv_image = cv2.imdecode(file_bytes, 1)\n",
        "    # st.image(image, caption=f\"Uploaded Image {img_array.shape[0:2]}\", use_column_width=True,)\n",
        "    # image = cv2.imread(img)\n",
        "    # rgb = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)\n",
        "    #convert image to Greyscale for haarcascade\n",
        "    # image = cv2.imread(image)\n",
        "    try:\n",
        "      pil_image = ima.convert('RGB') \n",
        "      # pil_image = ima\n",
        "      open_cv_image = np.array(pil_image)\n",
        "      cv2.imwrite(\"new.png\",open_cv_image)\n",
        "  # Convert RGB to BGR \n",
        "      image = open_cv_image[:, :, ::-1].copy()\n",
        "      gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "      faces = faceCascade.detectMultiScale(gray,\n",
        "                                          scaleFactor=1.1,\n",
        "                                          minNeighbors=5,\n",
        "                                          minSize=(60, 60),\n",
        "                                          flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "      \n",
        "      # the facial embeddings for face in input\n",
        "      encodings = face_recognition.face_encodings(image)\n",
        "      names = []\n",
        "      # loop over the facial embeddings incase\n",
        "      # we have multiple embeddings for multiple fcaes\n",
        "      for encoding in encodings:\n",
        "          #Compare encodings with encodings in data[\"encodings\"]\n",
        "          #Matches contain array with boolean values and True for the embeddings it matches closely\n",
        "          #and False for rest\n",
        "          matches = face_recognition.compare_faces(data[\"encodings\"],\n",
        "          encoding)\n",
        "          #set name =inknown if no encoding matches\n",
        "          name = \"Unknown\"\n",
        "          # check to see if we have found a match\n",
        "          if True in matches:\n",
        "              #Find positions at which we get True and store them\n",
        "              matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "              counts = {}\n",
        "              # loop over the matched indexes and maintain a count for\n",
        "              # each recognized face face\n",
        "              for i in matchedIdxs:\n",
        "                  #Check the names at respective indexes we stored in matchedIdxs\n",
        "                  name = data[\"names\"][i]\n",
        "                  #increase count for the name we got\n",
        "                  counts[name] = counts.get(name, 0) + 1\n",
        "                  #set name which has highest count\n",
        "                  name = max(counts, key=counts.get)\n",
        "              # update the list of names\n",
        "              names.append(name)\n",
        "              # loop over the recognized faces\n",
        "              for ((x, y, w, h), name) in zip(faces, names):\n",
        "                  # rescale the face coordinates\n",
        "                  # draw the predicted face name on the image\n",
        "                  cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                  cv2.putText(image, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                  0.75, (0, 255, 0), 2)\n",
        "          else: # To store the unknown new face with name\n",
        "              faces = faceCascade.detectMultiScale(gray,\n",
        "                                      scaleFactor=1.1,\n",
        "                                      minNeighbors=5,\n",
        "                                      minSize=(60, 60),\n",
        "                                      flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "          \n",
        "          cv2.imwrite('curr.png',image)\n",
        "          return name\n",
        "    except:\n",
        "      return \"Need GPU\"\n"
      ],
      "metadata": {
        "id": "RreFgu1X9THb"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "PzVWNEpBgyof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5430303e-02f9-48d8-9ed1-fe614814c649"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Salz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "def video(vid):\n",
        "  file = '../../../../..'+vid.name\n",
        "  # file = vid\n",
        "  video = cv2.VideoCapture(file)\n",
        "  # video.set(cv2.CAP_PROP_FPS, 10)\n",
        "  if (video.isOpened() == False):\n",
        "    print(\"Error reading video file\")\n",
        "  frame_width = int(video.get(3))\n",
        "  frame_height = int(video.get(4))\n",
        "  size = (frame_width, frame_height)\n",
        "\n",
        "# # Below VideoWriter object will create\n",
        "# # a frame of above defined The output\n",
        "# # is stored in 'filename.avi' file.\n",
        "  result = cv2.VideoWriter('filename.mp4',\n",
        "              cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "              10, size)\n",
        "    \n",
        "  while(True):\n",
        "    ret, frame = video.read()\n",
        "    if ret == True:\n",
        "\n",
        "      rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "      faces = faceCascade.detectMultiScale(rgb,\n",
        "                                          scaleFactor=1.1,\n",
        "                                          minNeighbors=5,\n",
        "                                          minSize=(60, 60),\n",
        "                                          flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "  \n",
        "      # convert the input frame from BGR to RGB \n",
        "      \n",
        "      # the facial embeddings for face in input\n",
        "      encodings = face_recognition.face_encodings(rgb)\n",
        "      names = []\n",
        "      # loop over the facial embeddings incase\n",
        "      # we have multiple embeddings for multiple fcaes\n",
        "      for encoding in encodings:\n",
        "      #Compare encodings with encodings in data[\"encodings\"]\n",
        "      #Matches contain array with boolean values and True for the embeddings it matches closely\n",
        "      #and False for rest\n",
        "          matches = face_recognition.compare_faces(data[\"encodings\"],\n",
        "          encoding)\n",
        "          #set name =inknown if no encoding matches\n",
        "          name = \"Unknown\"\n",
        "          # check to see if we have found a match\n",
        "          if True in matches:\n",
        "              #Find positions at which we get True and store them\n",
        "              matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "              counts = {}\n",
        "              # loop over the matched indexes and maintain a count for\n",
        "              # each recognized face face\n",
        "              for i in matchedIdxs:\n",
        "                  #Check the names at respective indexes we stored in matchedIdxs\n",
        "                  name = data[\"names\"][i]\n",
        "                  #increase count for the name we got\n",
        "                  counts[name] = counts.get(name, 0) + 1\n",
        "              #set name which has highest count\n",
        "              name = max(counts, key=counts.get)\n",
        "  \n",
        "  \n",
        "          # update the list of names\n",
        "          names.append(name)\n",
        "          # loop over the recognized faces\n",
        "          for ((x, y, w, h), name) in zip(faces, names):\n",
        "              # rescale the face coordinates\n",
        "              # draw the predicted face name on the image\n",
        "              cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "              cv2.putText(frame, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "              0.75, (0, 255, 0), 2)\n",
        "      result.write(frame)\n",
        "      # cv2_imshow(frame)\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "\n",
        "    # Break the loop\n",
        "    else:\n",
        "      break\n",
        "\n",
        "    print(pathlib.Path('../..'+'/content/Salz/filename.mp4').resolve())\n",
        "\n",
        "  # print(\"The video was successfully saved\")\n",
        "  return '../..'+'/content/Salz/filename.mp4'"
      ],
      "metadata": {
        "id": "pXTnQzVVj3xm"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# disp= Image.open(\"/content/drive/MyDrive/Salz/app/sherlock.png\")\n",
        "# det = Image.open(\"/content/drive/MyDrive/Salz/app/Screenshot (47).png\")\n",
        "# display = np.asarray(disp)\n",
        "# detail = np.asarray(det)"
      ],
      "metadata": {
        "id": "IQuYFZXXtf-H"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AG = input(\"Enter Possible Age and Gender and Ethnicity for the Person:\")\n",
        "# facftop = input (\"Provide Desciptors for Hair and Eyebrows and Eyes\")\n",
        "# facfmid =input (\"Describe Skin Color, Blemishes, Nose Structure\")\n",
        "# facfbot = input (\"Descibe Facial Shape, build , chin structure in as much detail as possible\")"
      ],
      "metadata": {
        "id": "dbC6gKVJsUob"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(AG,facftop,facfmid,facfbot):  \n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=\"Generate Facial Description of person from the following desciptors-Realistic facial portrait sketch of \" + AG + facftop + facfmid + facfbot,\n",
        "        temperature=0.1,\n",
        "        max_tokens=256,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return (response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "3rBXlAj1LGSL"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = \"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\"\n",
        "# os.getenv()\n",
        "PROMPT = \"Ankit went to the market. He called Raj then.\"\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=f\"Given a prompt, extrapolate as many relationships as possible from it and provide a list of updates.\\n\\nIf an update is a relationship, provide [ENTITY 1, RELATIONSHIP, ENTITY 2]. The relationship is directed, so the order matters.\\n\\nIf an update is related to deleting an entity, provide [\\\"DELETE\\\", ENTITY].\\n\\nExample:\\nprompt: Alice is Bob's roommate. Alice likes music. Her roommate likes sports\\nupdates:\\n[[\\\"Alice\\\", \\\"roommate\\\", \\\"Bob\\\"],[\\\"Alice\\\",\\\"likes\\\",\\\"music\\\"],[\\\"Bob\\\",\\\"likes\\\",\\\"sports\\\"]]\\n\\nprompt: {PROMPT}\\nupdates:\",\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")"
      ],
      "metadata": {
        "id": "vg4mLdb-S8XV"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = response[\"choices\"][0][\"text\"]\n",
        "t = t[2:]\n",
        "t = t.replace(\"[\",'').replace(\"]\",\"\")\n",
        "t = t.split(\",\")\n",
        "r = []\n",
        "for i in range(len(t)//3):\n",
        "  r.append(t[3*i:3*i+3])\n",
        "r"
      ],
      "metadata": {
        "id": "05LyPGejTnBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1899d7-32ea-447f-f1aa-a6054b133278"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['\"Ankit\"', '\"went to\"', '\"market\"'], ['\"Ankit\"', '\"called\"', '\"Raj\"']]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQUs4Yk8S-qP"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r01ADmx9UCoE"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "t"
      ],
      "metadata": {
        "id": "j94JecQIUCqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47943c1e-0788-4d7a-bd6d-479565af5ec8"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"Ankit\"', '\"went to\"', '\"market\"', '\"Ankit\"', '\"called\"', '\"Raj\"']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# response for: Ankit went to the market. He called Raj then"
      ],
      "metadata": {
        "id": "Hbz7XruPUCs5"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fOmfIDkgVLmV"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_edge_labels(t:list):\n",
        "  dct = {}\n",
        "  length_of_t = len(t)\n",
        "  for i in range(length_of_t):\n",
        "    t[i][0] = t[i][0].replace('\"',\"\").replace(\"'\",\"\").strip()\n",
        "    t[i][2] = t[i][2].replace('\"',\"\").replace(\"'\",\"\").strip()\n",
        "    t[i][1] = t[i][1].replace('\"',\"\").replace(\"'\",\"\")\n",
        "    dct[(t[i][0],t[i][2] )] =  t[i][1]\n",
        "  return dct\n",
        "def knowledge_graph(prompt): \n",
        "  \n",
        "  response = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=f\"\"\"Given a prompt, extrapolate as many relationships as possible from it and provide a list of updates.\\n\\nIf an update is a relationship, provide \n",
        "     [ENTITY 1, RELATIONSHIP, ENTITY 2]. The relationship is directed, so the order matters.\\n\\nIf an update is related to deleting an entity, provide [\\\"DELETE\\\", ENTITY].\\n\\nExample:\\nprompt: Alice is Bob's roommate. Alice likes music. Her roommate likes sports\\nupdates:\\n[[\\\"Alice\\\", \\\"roommate\\\", \\\"Bob\\\"],[\\\"Alice\\\",\\\"likes\\\",\\\"music\\\"],\n",
        "     [\\\"Bob\\\",\\\"likes\\\",\\\"sports\\\"]]\\n\\nprompt: {prompt}\\nupdates:\"\"\",\n",
        "    temperature=0,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  r = response[\"choices\"][0][\"text\"]\n",
        "  r = r[2:]\n",
        "  r = r.replace(\"[\",'').replace(\"]\",\"\")\n",
        "  r = r.split(\",\")\n",
        "  t = []\n",
        "  for i in range(len(r)//3):\n",
        "    t.append(r[3*i:3*i+3])\n",
        "  # t = [['\"Ankit\"', '\"went_to\"', '\"market\"'], ['\"Ankit\"', '\"called\"', '\"Raj\"']]\n",
        "  import networkx as nx\n",
        "  import random\n",
        "  print(t)\n",
        "  G = nx.Graph()\n",
        "  new_nodes = []\n",
        "  print('Edge labels')\n",
        "  edge_labels = get_edge_labels(t)\n",
        "  print(edge_labels)\n",
        "  print(f't after edge labesl = {t}')\n",
        "  for i in t:\n",
        "    if not i[0] in new_nodes:\n",
        "      new_nodes.append(i[0])\n",
        "      G.add_node(i[0])\n",
        "    if not i[2] in new_nodes:\n",
        "      new_nodes.append(i[2])\n",
        "      G.add_node(i[2])\n",
        "    # G.add_node(i[0])\n",
        "    # G.add_node(i[2])\n",
        "    G.add_edge(i[0],i[2])\n",
        "  pos = nx.spring_layout(G)\n",
        "  nx.draw(G,pos,labels={node: node for node in G.nodes()})\n",
        "  \n",
        "  x = nx.draw_networkx_edge_labels(\n",
        "      G, pos,\n",
        "      edge_labels=edge_labels,\n",
        "      font_color='red'\n",
        "  )\n",
        "  # print(x)\n",
        "  random_name = f'generated_img_{random.randint(1,100000)}.png'\n",
        "  plt.savefig(f\"/content/{random_name}\")\n",
        "  plt.clf()\n",
        "  img = Image.open(f\"/content/{random_name}\")\n",
        "  os.remove(f\"/content/{random_name}\")\n",
        "  print(dir(img))\n",
        "  print(img.filename)\n",
        "  return np.asarray(img)\n",
        "  \n",
        "c =knowledge_graph(\"Alice went to office. Called bob. Went to grocery shopping. Then went home\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Nj2lRR9lNocE",
        "outputId": "bda0f5ff-dfa6-4833-cb36-0ba7f293100f"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['\"Alice\"', '\"went to\"', '\"office\"'], ['\"Alice\"', '\"called\"', '\"Bob\"'], ['\"Alice\"', '\"went to\"', '\"grocery shopping\"'], ['\"Alice\"', '\"went to\"', '\"home\"']]\n",
            "Edge labels\n",
            "{('Alice', 'office'): 'went to', ('Alice', 'Bob'): 'called', ('Alice', 'grocery shopping'): 'went to', ('Alice', 'home'): 'went to'}\n",
            "t after edge labesl = [['Alice', 'went to', 'office'], ['Alice', 'called', 'Bob'], ['Alice', 'went to', 'grocery shopping'], ['Alice', 'went to', 'home']]\n",
            "['_Image__transformer', '_PngImageFile__fp', '_PngImageFile__frame', '_PngImageFile__prepare_idat', '__array__', '__class__', '__copy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_category', '_close__fp', '_close_exclusive_fp_after_loading', '_copy', '_crop', '_dump', '_ensure_mutable', '_exclusive_fp', '_exif', '_expand', '_get_safe_box', '_getexif', '_getxmp', '_min_frame', '_new', '_open', '_repr_png_', '_seek', '_seek_check', '_size', '_text', 'alpha_composite', 'close', 'convert', 'copy', 'crop', 'custom_mimetype', 'decoderconfig', 'decodermaxblock', 'default_image', 'draft', 'effect_spread', 'entropy', 'filename', 'filter', 'format', 'format_description', 'fp', 'frombytes', 'get_format_mimetype', 'getbands', 'getbbox', 'getchannel', 'getcolors', 'getdata', 'getexif', 'getextrema', 'getim', 'getpalette', 'getpixel', 'getprojection', 'getxmp', 'height', 'histogram', 'im', 'info', 'is_animated', 'load', 'load_end', 'load_prepare', 'load_read', 'mode', 'n_frames', 'palette', 'paste', 'png', 'point', 'private_chunks', 'putalpha', 'putdata', 'putpalette', 'putpixel', 'pyaccess', 'quantize', 'readonly', 'reduce', 'remap_palette', 'resize', 'rotate', 'save', 'seek', 'show', 'size', 'split', 'tell', 'text', 'thumbnail', 'tile', 'tobitmap', 'tobytes', 'toqimage', 'toqpixmap', 'transform', 'transpose', 'verify', 'width']\n",
            "/content/generated_img_26677.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from datetime import datetime\n",
        "import gradio as gr\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "gr.HTML(\"\"\"\n",
        "body{\n",
        " color: black\n",
        "}\"\"\")\n",
        "disp_url = \"https://i.ibb.co/TP4ddc6/sherlock.png\"\n",
        "det_url = \"https://i.ibb.co/Ms1jcDv/104cc37752fa.png\"\n",
        "with gr.Blocks(css=\".gradio-container {background-color: #F0FFFF}\") as demo:\n",
        "  gr.Markdown(\"<h1 style='color:black;font-family:monospace;text-align:center'>Sherlock's Phoeniks</h1>\")\n",
        "  gr.Markdown(\"<h4 style='color:black;font-family:monospace'>Facial Recognition using Generative AI - ChatGPT+StableDiffusion,utilizing Computer Vision and Google Search API</h4>\")\n",
        "  # gr.Image(display).style(height=400, width=1200)\n",
        "  gr.HTML(value=\"<img src='https://i.ibb.co/TP4ddc6/sherlock.png' alt='Flow Diagram' width='1200' height='300'/>\")\n",
        "  # gr.Markdown(\"! [title](https://pixabay.com/photos/tree-sunset-clouds-sky-silhouette-736885/)\")\n",
        "  gr.Markdown(\"\"\"<p style='color:black;font-family:monospace'>Our Sherlock's Phoeniks Search Squad solution is a facial recognition \n",
        "system that utilizes generative AI models like ChatGPT and stable \n",
        "diffusion/Dalle, as well as computer vision techniques, to identify and locate \n",
        "missing persons in real time . The system will take input in the form of text \n",
        "describing the appearance of the missing person, as well as raw images \n",
        "such as sketches, CCTV footage, or blurry photos. The algorithm will then \n",
        "search through internal databases and internet/social media platforms like \n",
        "Facebook and Twitter to find matches and potentially identify the missing \n",
        "person. This system has the potential to significantly aid Police and \n",
        "Investigating agencies in their efforts to locate and bring missing persons \n",
        "home</p>\"\"\")\n",
        "  gr.HTML(value=\"<img src='https://i.ibb.co/Ms1jcDv/104cc37752fa.png' alt='Flow Diagram' style='height:500px;width:1200px'>\")\n",
        "  # gr.Image(detail).style(height=400, width=1200)\n",
        "  with gr.Accordion(\"Generate Prompt\",open=False):\n",
        "    gr.HTML(value=\"<img src='https://i.ibb.co/hm1hGsP/503e7730-b23c-401a-a73a-3fef2eb074d9.jpg' alt='Generate Prompt' width='1200' height='300'/>\")  \n",
        "    print('DEBUG: FIRST WITH')\n",
        "    print('DEBUG: FIRST WITH')\n",
        "    gr.Markdown(\"**Generate Prompt from the face description for image generation**\")\n",
        "    \n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        print('DEBUG: SECOND WITH')\n",
        "        # seed = gr.Text(label=\"Input Phrase\")\n",
        "        text1_1 = gr.Text(label=\"Enter Possible Age and Gender and Ethnicity for the Person\")\n",
        "        text1_2 = gr.Text(label=\"Provide Desciptors for Hair and Eyebrows and Eyes\")\n",
        "        text1_3 = gr.Text(label=\"Describe Skin Color, Blemishes, Nose Structure\")\n",
        "        text1_4 = gr.Text(label=\"Descibe Facial Shape, build , chin structure in as much detail as possible\")\n",
        "        print(f'{text1_1=}')\n",
        "        print(f'{text1_2=}')\n",
        "        print(f'{text1_3=}')\n",
        "        print(f'{text1_4=}')\n",
        "\n",
        "        \n",
        "      with gr.Column():\n",
        "        # seed = gr.Text(label=\"Input Phrase\")\n",
        "        text2 = gr.Text(label=\"Generated Phrase\")\n",
        "        print(text2,'-------------')\n",
        "  abtn = gr.Button(\"Generate mugshot phrase\")\n",
        "  abtn.click(generate_prompt, inputs=[text1_1,text1_2,text1_3,text1_4], outputs=text2)\n",
        "  with gr.Accordion(\"Generate MugShot\",open=False):\n",
        "    gr.Markdown(\"**Generate MugShot from the input prompt using Dall-E**\")\n",
        "    gr.Markdown(\"**Use Dall E  or StableDiffusion Image Generation for text to image**\")\n",
        "    # gr.HTML(value=\"<img src='https://i.ibb.co/9WsBLD0/21aa355d-5005-4fbb-bf50-4ded05e6075e.jpg' alt='Genrate image from prompt' style='height:500px;width:1200px'>\")  \n",
        "    model = gr.Radio([\"StableDiffusion\"])\n",
        "    print(dir(model))\n",
        "    with open('/content/logging.log',mode='a') as log_f: log_f.write(f'{datetime.now()} Using model for General Mugshot: {model.value}'+'\\n')\n",
        "    with gr.Row():  \n",
        "      with gr.Column():\n",
        "        # seed = gr.Text(label=\"Input Phrase\")\n",
        "        text3 = gr.Text(label=\"Input Phrase\")\n",
        "      with gr.Column():\n",
        "        # seed = gr.Text(label=\"Input Phrase\")\n",
        "        im1 = gr.Image()\n",
        "    bbtn = gr.Button(\"Image from description\")\n",
        "    bbtn.click(generate, inputs=[text3,model], outputs=im1)\n",
        "\n",
        "  with gr.Accordion(\"Image from Sketch\",open=False):\n",
        "    gr.Markdown(\"**Get Enhanced Image from sketch and desired input promt using StableDiffusion**\")\n",
        "    with gr.Accordion(\"Pre-drawn Sketch\",open=False):\n",
        "      gr.Markdown(\"**Generate Colorful Image from pre drawn sketch**\")\n",
        "      gr.Markdown(\"**Use StableDiffusion Depth2Image for Image to Image transformation**\")\n",
        "      # gr.HTML(value=\"<img src='https://i.ibb.co/H4k0B7k/c58db90d-9479-411d-aaff-15863d2479a0.jpg' alt='Generate Image from sketch' style='height:500px;width:1200px'>\")  \n",
        "      with gr.Row():  \n",
        "        with gr.Column():\n",
        "          # seed = gr.Text(label=\"Input Phrase\")\n",
        "          text4 = gr.Text(label=\"Prompt\")\n",
        "          text5 = gr.Text(label=\"Negative Prompt\")\n",
        "          im2 = gr.Image(type=\"pil\")\n",
        "        with gr.Column():\n",
        "          # seed = gr.Text(label=\"Input Phrase\")\n",
        "          im3 = gr.Image()\n",
        "      cbtn = gr.Button(\"Sketch to color\")\n",
        "      cbtn.click(transform, inputs=[im2,text4,text5], outputs=im3)\n",
        "    with gr.Accordion(\"Draw Sketch\",open=False,css=\"\"):\n",
        "      gr.Markdown(\"**Draw sketch on your own and give text description of features**\")\n",
        "      gr.Markdown(\"**Generate Colorful Image using StableDiffusionImg2ImgPipeline**\")\n",
        "      with gr.Row():\n",
        "        with gr.Column():\n",
        "          # seed = gr.Text(label=\"Input Phrase\")\n",
        "          text6 = gr.Text(label=\"Prompt\")\n",
        "          text7 = gr.Text(label=\"Negative Prompt\")\n",
        "          # im1 = gr.Image(type=\"pil\",interactive=True)\n",
        "          im4 = gr.Sketchpad(shape=(256,256),invert_colors=False,type=\"pil\")\n",
        "        with gr.Column():\n",
        "          # seed = gr.Text(label=\"Input Phrase\")\n",
        "          im5 = gr.Image()\n",
        "      ebtn = gr.Button(\"Draw Sketch to color\")\n",
        "      ebtn.click(transform1, inputs=[im4,text6,text7], outputs=im5)\n",
        "\n",
        "  with gr.Accordion(\"Check Database\",open=False):\n",
        "    gr.Markdown(\"**Check if the image matches any image in our database using face_recognition**\")\n",
        "    gr.Markdown(\"**Use Face Recognition, Face Detection and Computer Vision to match images**\")\n",
        "    # gr.HTML(value=\"<img src='https://i.ibb.co/bBnDxqT/c5d2fe61-4b99-4cbc-934c-1ae9edfa4386.png' alt='Check Database' width='1200' height='300'/>\")    \n",
        "    \n",
        "    with gr.Row():  \n",
        "      with gr.Column():\n",
        "        # seed = gr.Text(label=\"Input Phrase\")\n",
        "        im6 = gr.Image(type=\"pil\")\n",
        "      with gr.Column():\n",
        "        # seed = gr.Text(label=\"Input Phrase\")\n",
        "        text8 = gr.Text(label=\"Identified Name\")\n",
        "    fbtn = gr.Button(\"Find the Name\")\n",
        "    fbtn.click(check_database, inputs=im6, outputs=text8)\n",
        "\n",
        "  \n",
        "\n",
        "  with gr.Accordion(\"Search Google\",open=False):\n",
        "    gr.Markdown(\"**Check if the image is present on the Internet**\")\n",
        "    gr.Markdown(\"**Using Google search api to search the image on Web**\")\n",
        "    # gr.HTML(value=\"<img src='https://i.ibb.co/9v7vwVF/58f827cc-e24a-4df8-ab0f-40204d0940ec.jpg' alt='Check Google' width='1200' height='300'/>\")    \n",
        "      \n",
        "    with gr.Row():  \n",
        "      with gr.Column():\n",
        "        # seed = gr.Text(label=\"Input Phrase\")\n",
        "        im7 = gr.Image(type=\"pil\")\n",
        "      with gr.Column():\n",
        "        text9 = gr.Text(label=\"Identified Title\")\n",
        "        im8 = gr.Image()\n",
        "    gbtn = gr.Button(\"Find the Name\")\n",
        "    gbtn.click(google_search, inputs=im7, outputs=[text9,im8])\n",
        "  with gr.Accordion(\"Generate Knowledge Graph\",open=False):\n",
        "    gr.Markdown(\"**Genrate KNowledge Graph**\")\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        prompt_to_generate_graph = gr.Text()\n",
        "      with gr.Column():\n",
        "        generated_graph_pic = gr.Image()\n",
        "\n",
        "    generate_knowledge_graph = gr.Button(\"Generate Knowledge Graph\")\n",
        "    generate_knowledge_graph.click(knowledge_graph, inputs=prompt_to_generate_graph, outputs=generated_graph_pic)\n",
        "    \n",
        "  with gr.Accordion(\"Search in CCTV footage\",open=False):\n",
        "    gr.Markdown(\"**Upload a video to identify missing person in the footage**\")\n",
        "    # gr.HTML(value=\"<img src='https://i.ibb.co/H7t0R5C/bb71faf0-f86f-4064-b796-7a4dea6efdc7.jpg' alt='Check cctv' width='1200' height='300'/>\")  \n",
        "    with gr.Row(): \n",
        "      with gr.Column():\n",
        "        fil1 = gr.File(type=\"file\")\n",
        "      with gr.Column():\n",
        "        vid2 = gr.Video()\n",
        "    hbtn = gr.Button(\"Video\")\n",
        "    hbtn.click(video, inputs=fil1, outputs=vid2)\n",
        "  \n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "6PCC3dmR9TMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        },
        "outputId": "38409c50-51a3-4d77-f637-4ad9d533017b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Accordion, please remove them: {'css': ''}\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Salz\n",
            "DEBUG: FIRST WITH\n",
            "DEBUG: FIRST WITH\n",
            "DEBUG: SECOND WITH\n",
            "text1_1=textbox\n",
            "text1_2=textbox\n",
            "text1_3=textbox\n",
            "text1_4=textbox\n",
            "textbox -------------\n",
            "['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_id', '_skip_init_processing', '_style', 'add_interactive_to_config', 'as_example', 'attach_load_event', 'change', 'choices', 'cleared_value', 'deserialize', 'elem_id', 'generate_sample', 'get_block_name', 'get_config', 'get_expected_parent', 'get_interpretation_neighbors', 'get_interpretation_scores', 'get_load_fn_and_initial_value', 'get_specific_update', 'info', 'interactive', 'label', 'load_event', 'load_event_to_attach', 'parent', 'postprocess', 'preprocess', 'render', 'root_url', 'serialize', 'set_event_trigger', 'set_interpret_parameters', 'share_token', 'show_label', 'style', 'test_input', 'type', 'unrender', 'update', 'value', 'visible']\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45c8df2194ab4fbf8773a4f1206552e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb84d36ed22c45669c1cd05173cd4714",
              "IPY_MODEL_a9ef07cddbb24ea389890e935c8190cf",
              "IPY_MODEL_42b3b6757a3f41efa1bd10b544d523c8"
            ],
            "layout": "IPY_MODEL_0cffc9d5a633449dbce2ad11d3ceab63"
          }
        },
        "eb84d36ed22c45669c1cd05173cd4714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f319027e5b384a5588bc36111ecab092",
            "placeholder": "​",
            "style": "IPY_MODEL_c6ddfd17c6e846bc85842574460d3969",
            "value": "Fetching 15 files: 100%"
          }
        },
        "a9ef07cddbb24ea389890e935c8190cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4100192b5cb44efb99ab36eee808966",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_647e89ebd9cc415cbe970fef56fa9511",
            "value": 15
          }
        },
        "42b3b6757a3f41efa1bd10b544d523c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7d351928da45b8b79f62e351f26361",
            "placeholder": "​",
            "style": "IPY_MODEL_c6d07b87035e4a41b0f135dcb01d5392",
            "value": " 15/15 [00:00&lt;00:00, 278.66it/s]"
          }
        },
        "0cffc9d5a633449dbce2ad11d3ceab63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f319027e5b384a5588bc36111ecab092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6ddfd17c6e846bc85842574460d3969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4100192b5cb44efb99ab36eee808966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "647e89ebd9cc415cbe970fef56fa9511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c7d351928da45b8b79f62e351f26361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6d07b87035e4a41b0f135dcb01d5392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd4f2c662ed243c0ba8687bbe1437a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_176022374e9d4776acee17d165414936",
              "IPY_MODEL_80057139469c49e9b130edda63159e30",
              "IPY_MODEL_6bc059be8bbb4feb86e8da7c39607b5d"
            ],
            "layout": "IPY_MODEL_618edea2de804694affa5cec90d49db8"
          }
        },
        "176022374e9d4776acee17d165414936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f2b1bbf19af4b099334a67ad9399bd0",
            "placeholder": "​",
            "style": "IPY_MODEL_6b2ede83d687421d9269ed11fec36a25",
            "value": "Fetching 15 files: 100%"
          }
        },
        "80057139469c49e9b130edda63159e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8af98c87f3a643dc8a62416f1fef24b8",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a67d5a754884d58acb961566515ce12",
            "value": 15
          }
        },
        "6bc059be8bbb4feb86e8da7c39607b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b73e638f26194f19972d94e23aee4081",
            "placeholder": "​",
            "style": "IPY_MODEL_c3667d3bdc7f469dbec821ff1bdbbc59",
            "value": " 15/15 [00:00&lt;00:00, 271.93it/s]"
          }
        },
        "618edea2de804694affa5cec90d49db8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f2b1bbf19af4b099334a67ad9399bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2ede83d687421d9269ed11fec36a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8af98c87f3a643dc8a62416f1fef24b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a67d5a754884d58acb961566515ce12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b73e638f26194f19972d94e23aee4081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3667d3bdc7f469dbec821ff1bdbbc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}